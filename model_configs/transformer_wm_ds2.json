{
"input_size": 35,
 "embedding_size": 512,
 "num_heads": 4,
 "encoder_hidden_size": 512,
 "num_encoder_layers": 2,
 "num_decoder_layers": 2,
 "decoder_hidden_size": 256,
 "model_type": "transformer_wm"
 }